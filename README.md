# fine-tuning-gemma-2b

#What is Fine-Tuning?
Fine-tuning is the process of adjusting the parameters of a pre-trained large language model to a specific task or domain. Although pre-trained language models like GPT possess vast language knowledge, they lack specialization in specific areas.

Here, gemma-2b model is used for fine-tuning with the news dataset.
The dataset consists of 2 features. ie, "INSTRUCTION" and "RESPONSE".

I have used PEFT method with LORA for making the process faster.
